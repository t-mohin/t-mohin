{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-mohin/t-mohin/blob/main/Resume_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxG8CaW0zFBI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf\n",
        "!pip install textract\n",
        "!apt-get install unrtf\n",
        "!pip install --upgrade pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iYOmjZ43d-C",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMIelTgX3-Zv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install pdfplumber pdfminer docx2txt textract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wGMQeWv2kmE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TbyYPF36ADl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!apt-get install -y antiword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq9xWd1o4MoK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pdfplumber\n",
        "import docx2txt\n",
        "import textract\n",
        "import glob\n",
        "import csv\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "# Precompiled regex patterns\n",
        "email_pattern = re.compile(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+')\n",
        "phone_pattern = re.compile(r'(\\d{3}[-.\\s]??\\d{3}[-.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-.\\s]??\\d{4}|\\d{3}[-.\\s]??\\d{4})')\n",
        "name_pattern = re.compile(r'(?i)(?:name|^)[\\s:]*([A-Z][a-z]+(?:\\s[A-Z][a-z]+)+)')\n",
        "location_pattern = re.compile(r'\\b(?:Alabama|Alaska|Arizona|Arkansas|California|Colorado|Connecticut|Delaware|Florida|Georgia|Hawaii|Idaho|Illinois|Indiana|Iowa|Kansas|Kentucky|Louisiana|Maine|Maryland|Massachusetts|Michigan|Minnesota|Mississippi|Missouri|Montana|Nebraska|Nevada|New Hampshire|New Jersey|New Mexico|New York|North Carolina|North Dakota|Ohio|Oklahoma|Oregon|Pennsylvania|Rhode Island|South Carolina|South Dakota|Tennessee|Texas|Utah|Vermont|Virginia|Washington|West Virginia|Wisconsin|Wyoming)\\b', re.IGNORECASE)\n",
        "job_title_pattern = re.compile(r'\\b(?:Software Engineer|Data Scientist|Project Manager|Web Developer|Product Manager|Business Analyst|Graphic Designer|Consultant|Sales Manager|Marketing Manager|Quality Assurance|Senior Software Developer|IT|DevOps Engineer|Systems Administrator|Network Engineer|Database Administrator|Security Analyst|Data Analyst|Machine Learning Engineer|Cloud Engineer|Full Stack Developer|Frontend Developer|Backend Developer|Mobile Developer|UI/UX Designer|Scrum Master|Technical Support Specialist|IT Manager|CTO|CIO|Technical Lead|Engineering Manager|Non-Technical Role|Customer Service Representative|Retail Sales Associate|Administrative Assistant|Human Resources Specialist|Accountant|Financial Analyst|Executive Assistant)\\b', re.IGNORECASE)\n",
        "\n",
        "def extract_text(file_path):\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "    text = ''\n",
        "    try:\n",
        "        if ext == '.pdf':\n",
        "            with pdfplumber.open(file_path) as pdf:\n",
        "                text = ''.join(page.extract_text() for page in pdf.pages)\n",
        "        elif ext == '.docx':\n",
        "            text = docx2txt.process(file_path)\n",
        "        elif ext == '.doc':\n",
        "            text = textract.process(file_path).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {file_path}: {e}\")\n",
        "    return text\n",
        "\n",
        "def extract_info(text, file_name):\n",
        "    emails = email_pattern.findall(text)\n",
        "    phones = phone_pattern.findall(text)\n",
        "    names = name_pattern.findall(text)\n",
        "    locations = location_pattern.findall(text)\n",
        "    job_titles = job_title_pattern.findall(text)\n",
        "\n",
        "    # Handle special cases for names\n",
        "    if not names or names[0].strip().lower() in ('resume of', 'resume updated', 'professional summary'):\n",
        "        name = file_name\n",
        "    else:\n",
        "        name = names[0].strip()\n",
        "\n",
        "    # If the detected name is a job title, iterate through text lines to find a valid name\n",
        "    if re.match(job_title_pattern, name):\n",
        "        for line in text.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if re.match(name_pattern, line) and not re.match(job_title_pattern, line):\n",
        "                name = line.strip()\n",
        "                break\n",
        "\n",
        "    email = emails[0] if emails else ''\n",
        "    phone = phones[0] if phones else ''\n",
        "    location = ' '.join(locations[:5]) if locations else ''\n",
        "    job_title = job_titles[0] if job_titles else 'Non-Technical Role'\n",
        "\n",
        "    return {\n",
        "        'Name': name,\n",
        "        'Email': email,\n",
        "        'Phone': phone,\n",
        "        'Location': location,\n",
        "        'Job Title': job_title\n",
        "    }\n",
        "\n",
        "def process_file(file_path):\n",
        "    text = extract_text(file_path)\n",
        "    if text:\n",
        "        file_name = os.path.splitext(os.path.basename(file_path))[0].replace('Copy of ', '').split()[0].strip()\n",
        "        return extract_info(text, file_name)\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    resumes_dir = '/content/drive/MyDrive/Resumes'\n",
        "    output_csv = '/content/drive/MyDrive/Extracted_Resume_Info.csv'\n",
        "\n",
        "    files = glob.glob(os.path.join(resumes_dir, '*'))\n",
        "\n",
        "    # Using ProcessPoolExecutor for parallel processing\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        futures = {executor.submit(process_file, file): file for file in files}\n",
        "\n",
        "    extracted_info = []\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            extracted_info.append(result)\n",
        "\n",
        "    # Writing results to CSV\n",
        "    with open(output_csv, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['Name', 'Email', 'Phone', 'Location', 'Job Title'])\n",
        "        writer.writeheader()\n",
        "        for info in extracted_info:\n",
        "            writer.writerow(info)\n",
        "\n",
        "    print(f\"Extraction complete. Information saved to {output_csv}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xY0LoCqPKxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7a5bbcb1-9663-4766-9f46-f2e54cae0678"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a871e31b-8ee5-4799-8315-6fa871e9f970\", \"Extracted_Resume_Info.csv\", 596779)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Define the path to the CSV file\n",
        "output_csv = '/content/drive/MyDrive/Extracted_Resume_Info.csv'\n",
        "\n",
        "# Download the CSV file\n",
        "files.download(output_csv)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}